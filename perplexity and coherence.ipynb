{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('corpus.txt',errors = 'ignore')\n",
    "content = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_replace = ['\\n', '.', '\\'', ',', '(', ')', '-','+',':','<','>','/','\"','\"']\n",
    "for i in list_replace:\n",
    "    content = content.replace(i, ' ') #Replace special symbols in the file with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = content.lower() #Require all words to be lowercase\n",
    "wordlist = content.split()\n",
    "worddict = set(wordlist) #Build my own dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_stopwords = open('cleanup_words.txt',errors = 'ignore') #Import the stop word list \n",
    "stopwords = open_stopwords.readlines()\n",
    "open_stopwords.close()\n",
    "stopwords[:8] #Observe the stop word format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stopwords)):\n",
    "    stopwords[i] = stopwords[i].strip() \n",
    "stopwords[:8] #Observe the stop word format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stopwords:\n",
    "    worddict.discard(i) #Remove stop words from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worddict_list = list(worddict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from snownlp import seg\n",
    "from snownlp import SnowNLP\n",
    "from snownlp import sentiment\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "maxInt = sys.maxsize\n",
    "decrement = True\n",
    "while decrement:\n",
    "    decrement = False\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "        decrement = True\n",
    "worddict_list = list(worddict), header = 0, index_col = False, engine='python',encoding = 'utf-8')\n",
    "csv_data = comment[[(len(str(x)) > 100) for x in comment]]\n",
    "print(csv_data.shape)\n",
    "\n",
    "# 构造corpus\n",
    "train = []\n",
    "for i in range(csv_data.shape[0]):\n",
    "    comment = csv_data.iloc[i,7].split()\n",
    "    train.append(comment)\n",
    "    \n",
    "id2word = corpora.Dictionary(train)\n",
    "corpus = [ id2word.doc2bow(sentence) for sentence in train]\n",
    "\n",
    "# 一致性和困惑度计算\n",
    "coherence_values = []\n",
    "perplexity_values = []\n",
    "model_list = []\n",
    "\n",
    "for topic in range(15):\n",
    "    lda_model = gensim.models.LdaMulticore(corpus = corpus, num_topics=topic+1, id2word = id2word, random_state=100, chunksize=100, passes=10, per_word_topics=True)\n",
    "    perplexity = pow(2,-lda_model.log_perplexity(corpus)) \n",
    "    print(perplexity,end='   ')\n",
    "    perplexity_values.append(round(perplexity,3))\n",
    "    \n",
    "    model_list.append(lda_model)\n",
    "    coherencemodel = CoherenceModel(model=lda_model, texts=train, dictionary=id2word, coherence='c_v')\n",
    "    coherence_values.append(round(coherencemodel.get_coherence(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(1,21)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
